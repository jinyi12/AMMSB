import itertools

import torch
import torch.nn as nn


## Adapated from conditional-flow-matching to allow for variable depth
## github.com/atong01/conditional-flow-matching/blob/main/torchcfm/models/models.py
class MLP(nn.Module):
    def __init__(self, dim, out_dim=None, w=64, depth=2, time_varying=False):
        super().__init__()
        self.time_varying = time_varying
        self.act = nn.SELU()
        if out_dim is None:
            out_dim = dim
        _layers = [nn.Linear(dim + (1 if time_varying else 0), w),
                   self.act]
        for _ in range(depth):
            _layers.append(nn.Linear(w, w))
            _layers.append(self.act)
        _layers.append(nn.Linear(w, out_dim))
        self.net = nn.Sequential(*_layers)

    def forward(self, xt):
        return self.net(xt)


class ResidualBlock(nn.Module):
    """Two-layer residual block with layer norm stabilization."""

    def __init__(self, hidden_dim, activation_cls=nn.SELU):
        super().__init__()
        self.fc1 = nn.Linear(hidden_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.act = activation_cls()
        self.norm = nn.LayerNorm(hidden_dim)

    def forward(self, x):
        residual = x
        out = self.act(self.fc1(x))
        out = self.fc2(out)
        out = self.norm(residual + out)
        return self.act(out)


class ResNet(nn.Module):
    """Fully-connected ResNet for time-conditioned residual learning."""

    def __init__(self, dim, out_dim=None, w=64, depth=2, time_varying=False):
        super().__init__()
        self.time_varying = time_varying
        if out_dim is None:
            out_dim = dim

        input_dim = dim + (1 if time_varying else 0)
        self.input_layer = nn.Linear(input_dim, w)
        self.input_act = nn.SELU()
        self.blocks = nn.ModuleList(
            [ResidualBlock(w, activation_cls=nn.SELU) for _ in range(depth)]
        )
        self.output_layer = nn.Linear(w, out_dim)
        nn.init.zeros_(self.output_layer.weight)
        nn.init.zeros_(self.output_layer.bias)

    def forward(self, xt):
        h = self.input_act(self.input_layer(xt))
        for block in self.blocks:
            h = block(h)
        return self.output_layer(h)
    
class TimeEmbedding(nn.Module):
    def __init__(self, emb_dim=32):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(1, emb_dim),
            nn.SiLU(),
            nn.Linear(emb_dim, emb_dim),
        )

    def forward(self, s):  # s: (B, ...) , take last dim as time
        s = s[..., -1:]  # take last dim as time
        s = s.view(-1, 1)  # flatten to (B, 1)
        return self.mlp(s)

    
class FiLMLayer(nn.Module):
    def __init__(self, dim_h, dim_t):
        super().__init__()
        self.fc = nn.Linear(dim_h, dim_h)
        self.act = nn.SELU()
        self.to_gamma_beta = nn.Linear(dim_t, 2 * dim_h)

    def forward(self, h, t_emb):
        gamma, beta = self.to_gamma_beta(t_emb).chunk(2, dim=-1)  # (B,dim_h)
        h = self.fc(h)
        h = gamma * h + beta      # time-dependent scaling + shift
        return self.act(h)


class TimeFiLMMLP(nn.Module):
    def __init__(self, dim_x, dim_out, w=128, depth=3, t_dim=32):
        super().__init__()
        self.time_emb = TimeEmbedding(t_dim)
        self.in_fc = nn.Linear(dim_x, w)
        self.layers = nn.ModuleList([FiLMLayer(w, t_dim) for _ in range(depth)])
        self.out_fc = nn.Linear(w, dim_out)

    def forward(self, x, t):
        # x: (B, dim_x), t: (B, 1)
        t_emb = self.time_emb(t)      # (B, t_dim)
        h = self.in_fc(x)
        h = torch.nn.functional.selu(h)
        for layer in self.layers:
            h = layer(h, t_emb)
        return self.out_fc(h)



## Adapted from MIOFlow
## https://github.com/KrishnaswamyLab/MIOFlow/blob/main/MIOFlow/models.py
class AutoEncoder(nn.Module):
    def __init__(
        self,
        encoder_layers,
        decoder_layers=None,
        activation='Tanh'
    ):
        super().__init__()
        if decoder_layers is None:
            decoder_layers = [*encoder_layers[::-1]]

        encoder_shapes = list(zip(encoder_layers, encoder_layers[1:]))
        decoder_shapes = list(zip(decoder_layers, decoder_layers[1:]))

        encoder_linear = list(map(lambda a: nn.Linear(*a), encoder_shapes))
        decoder_linear = list(map(lambda a: nn.Linear(*a), decoder_shapes))

        encoder_riffle = list(
            itertools.chain(
                *zip(encoder_linear, itertools.repeat(getattr(nn, activation)()))
            )
        )[:-1]
        # encoder = nn.Sequential(*encoder_riffle).to(device)
        encoder = nn.Sequential(*encoder_riffle)

        decoder_riffle = list(
            itertools.chain(
                *zip(decoder_linear, itertools.repeat(getattr(nn, activation)()))
            )
        )[:-1]

        # decoder = nn.Sequential(*decoder_riffle).to(device)
        decoder = nn.Sequential(*decoder_riffle)

        self.encoder = encoder
        self.decoder = decoder

    def encode(self, x):
        return self.encoder(x)

    def decode(self, z):
        return self.decoder(z)

    def forward(self, x):
        return self.decoder(self.encoder(x))
