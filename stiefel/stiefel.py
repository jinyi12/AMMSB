from __future__ import annotations

import importlib
import os
from concurrent.futures import ThreadPoolExecutor
from functools import partial
from typing import Optional

import numpy as np
try:
    import cvxpy as cp  # type: ignore
except ModuleNotFoundError:  # optional dependency
    cp = None
from scipy.linalg import eigh
from numpy.typing import NDArray
from scipy.linalg import svd, logm, expm, qr, eig, expm
from scipy.stats import gamma
from .Stiefel_Aux import *
from .Stiefel_Exp_Log import Stiefel_Exp, Stiefel_Log



def stiefel_exp_batch(
    U0: np.ndarray,
    delta: np.ndarray,
    metric_alpha: float = 0.0,
    workers: Optional[int] = None,
    chunk_size: int = 8,
):
    """Evaluate multiple Stiefel exponentials that share the same base point.

    Parameters
    ----------
    U0:
        Reference base point on St(N, r) with shape ``(N, r)``.
    delta:
        Batch of tangent vectors with shape ``(batch_size, N, r)`` or a
        single tangent vector ``(N, r)``.
    metric_alpha:
        Metric parameter passed through to :func:`Stiefel_Exp`.
    workers:
        Optional number of worker threads. ``None`` uses ``min(cpu_count, batch)``
        and ``-1`` uses all available cores. Values ``<=1`` disable parallelism.
    chunk_size:
        Minimum batch size required before parallel execution is triggered.

    Returns
    -------
    np.ndarray
        Array of shape ``(batch_size, N, r)`` containing the exponential map
        evaluations.
    """

    delta = np.asarray(delta)
    if delta.ndim == 2:
        delta = delta[None, ...]

    batch_size = delta.shape[0]
    if batch_size == 0:
        return np.zeros((0,) + U0.shape, dtype=U0.dtype)

    chunk_size = max(1, int(chunk_size))

    if workers is None:
        cpu_count = os.cpu_count() or 1
        worker_count = min(cpu_count, batch_size)
    elif workers == -1:
        worker_count = os.cpu_count() or 1
    else:
        worker_count = max(1, min(int(workers), batch_size))

    use_parallel = worker_count > 1 and batch_size >= chunk_size

    single = partial(Stiefel_Exp, U0, metric_alpha=metric_alpha)

    if not use_parallel:
        results = [single(delta[i]) for i in range(batch_size)]
    else:
        with ThreadPoolExecutor(max_workers=worker_count) as executor:
            results = list(executor.map(single, delta))

    return np.stack(results, axis=0)


def batch_stiefel_log(U0, rob, tau, metric_alpha=0.0):
    """

    Performs the Stiefel logarithm for each rob with respect to the reference base point U0, the global diffusion map basis.

    Parameters:
    U0: reference base point on St(N,r) \in R^{Nxr}
    rob: list of points on St(N,r) \in R^{Nxr}
    tau: convergence threshold
    verbose: print convergence information

    Returns:
    Deltas: list of tangent vectors on TuSt(N,r) \in R^{Nxr}

    """

    Deltas = []

    for i in range(len(rob)):
        # last rob is the global diffusion map basis
        Delta, conv = Stiefel_Log(U0, rob[i], tau, metric_alpha=metric_alpha)
        Delta = np.real(Delta)
        Deltas.append(Delta)

    Deltas = np.array(Deltas)

    return Deltas


def calc_concen_param(rob: NDArray, Deltas):
    """

    Calculates the concentration parameter beta for the Dirichlet distribution.
    The betas are calculated with respect to the global diffusion map basis.
    The concentration parameter is calculated by solving a convex optimization problem.

    Parameters:
    rob: array of points (matrices) on St(N,r) \in R^{Nxr}
    Deltas: array of tangent vectors (matrices) on TuSt(N,r) \in R^{Nxr}

    """
    if cp is None:
        raise ModuleNotFoundError("cvxpy is required for calc_concen_param; install cvxpy to use this function.")
    num_models = len(rob) - 1
    X = np.reshape(Deltas[:num_models, :, :], (num_models, -1))
    H = X @ X.T
    f = np.zeros(num_models)
    Aeq = np.ones((1, num_models))
    beq = np.array([1])
    lb = np.full(num_models, 1e-15)
    # ub = np.ones(num_models)

    # Define and solve the CVXPY problem
    beta = cp.Variable(num_models)
    # prob = cp.Problem(cp.Minimize((1/2)*cp.quad_form(beta, H) + f.T @ beta),
    #                 [Aeq @ beta == beq,
    #                 beta >= lb,
    #                 beta <= ub])

    prob = cp.Problem(
        cp.Minimize((1 / 2) * cp.quad_form(beta, H) + f.T @ beta),
        [Aeq @ beta == beq, beta >= lb],
    )

    prob.solve(eps_abs=1e-10, eps_rel=1e-10, verbose=True)

    # correct beta due to numerical precision
    beta.value = np.maximum(beta.value, 1e-15)

    # Print result
    beta_value = beta.value
    print("beta =", ", ".join(map(str, beta_value)))

    return beta


def gen_tangent_samples(N_samples: int, beta: cp.Variable, X: NDArray, seed: int = 42):
    """

    Generates N_samples tangent samples on TuSt(N,r) \in R^{Nxr} with respect to the global diffusion map basis.
    The tangent samples are generated by sampling from a Dirichlet distribution.

    Parameters:
    N_samples: number of samples
    beta: concentration parameter of the Dirichlet distribution
    X: reshaped array of basis, where X = np.reshape(Deltas[:num_models, :, :], (num_models, -1))

    Returns:
    tangential_samples: array of tangent samples (matrices) on TuSt(N,r) \in R^{Nxr}

    """
    if cp is None:
        raise ModuleNotFoundError("cvxpy is required for gen_tangent_samples; install cvxpy to use this function.")

    np.random.seed(seed)

    # Generate gamma-distributed random numbers
    scale = 1
    # print(np.tile(beta.value, (N_samples, 1)))
    w = gamma.rvs(
        np.tile(beta.value, (N_samples, 1)),
        scale=scale,
        size=(N_samples, beta.shape[0]),
    )

    # Normalize the rows of w
    w = w / np.sum(w, axis=1, keepdims=True)

    # Compute the tangential samples
    tangential_samples = w @ X

    # # Sort the rows of w and get the indices
    I = np.argsort(w, axis=1)
    maxI = I[:, -1]

    return tangential_samples, maxI


def gen_convex_comb_samples(N_samples: int, beta: NDArray, X: NDArray, seed: int = 42):
    """

    Generates N_samples tangent samples on TuSt(N,r) \in R^{Nxr} with respect to the global diffusion map basis.
    The tangent samples are generated by sampling from a Dirichlet distribution.

    Parameters:
    N_samples: number of samples
    beta: concentration parameter of the Dirichlet distribution
    X: reshaped array of basis, where X = np.reshape(Deltas[:num_models, :, :], (num_models, -1))

    Returns:
    tangential_samples: array of tangent samples (matrices) on TuSt(N,r) \in R^{Nxr}

    """

    np.random.seed(seed)

    # Generate gamma-distributed random numbers
    scale = 1
    # print(np.tile(beta.value, (N_samples, 1)))
    w = gamma.rvs(
        np.tile(beta, (N_samples, 1)),
        scale=scale,
        size=(N_samples, beta.shape[0]),
    )

    # Normalize the rows of w
    w = w / np.sum(w, axis=1, keepdims=True)

    # Compute the tangential samples
    convex_comb_samples = w @ X

    # # Sort the rows of w and get the indices
    I = np.argsort(w, axis=1)
    maxI = I[:, -1]

    return convex_comb_samples, maxI


# def gen_stiefel_samples(N_samples: int, rob: NDArray, tau: float = 1e-4, verbose: bool = True):
def gen_stiefel_samples(
    N_samples: int, rob: NDArray, tau: float = 1e-4, metric_alpha=0.0
):
    """

    Generates N_samples stiefel samples on St(N,r) \in R^{Nxr} with respect to the global diffusion map basis.

    Parameters:
    N_samples: number of samples
    rob: list of points on St(N,r) \in R^{Nxr}
    tau: convergence threshold of the Stiefel logarithm
    verbose: print convergence information

    Returns:
    stiefel_samples: array of stiefel samples (matrices) on St(N,r) \in R^{Nxr}

    """

    # the global ROB as reference base point
    U0 = rob[-1]

    # number of models excluding the global ROB
    num_models = len(rob) - 1

    # rob has shape (num_models, n_points, n), where n_points is the number of points and n is the number of eigenvectors (order of samples)
    n_points = rob[0].shape[0]
    n = rob[0].shape[1]

    # get the tangent vectors deltas
    # Deltas = batch_stiefel_log(U0, rob, tau=tau, verbose=verbose)
    Deltas = batch_stiefel_log(U0, rob, tau=tau, metric_alpha=metric_alpha)

    # calculate the concentration parameter beta
    beta = calc_concen_param(rob, Deltas)

    # reshape Deltas for computing the tangential samples
    X = np.reshape(Deltas[:num_models, :, :], (num_models, -1))

    # compute tangential samples
    tangential_samples, maxI = gen_tangent_samples(N_samples, beta, X)

    # Reshape tangential_samples
    tangential_samples = np.reshape(tangential_samples, (N_samples, n_points, n))

    # Initialize stiefel_samples
    stiefel_samples = np.zeros(tangential_samples.shape)

    # Compute stiefel_samples
    for i in range(N_samples):
        delta = tangential_samples[i, :, :]
        stiefel_samples[i, :, :] = Stiefel_Exp(
            rob[-1], delta, metric_alpha=metric_alpha
        )

    return stiefel_samples, maxI, beta.value


def calc_frechet_mean_mat(samples, U0, eps, tau=1e-3):
    """

    Calculates the Frechet mean of a set of samples on St(N,r) \in R^{Nxr} with respect to the reference base point U0.
    Subject to the convergence threshold OF THE MEAN CALCULATION eps, the algorithm is guaranteed to converge.

    Parameters:
    samples: array of samples (matrices) on St(N,r) \in R^{Nxr}
    U0: reference base point on St(N,r) \in R^{Nxr}
    eps: convergence threshold of the Frechet mean calculation
    tau: convergence threshold of the Stiefel logarithm

    Returns:
    frechet_mean: Frechet mean of the samples (matrix) on St(N,r) \in R^{Nxr}

    """
    err = np.inf
    c = 1
    N_samples, d, r = samples.shape
    count = 0
    errs = []

    while err > eps:
        V_mean = np.zeros((d, r))
        for i in range(N_samples):
            Delta, conv = Stiefel_Log(U0, samples[i, :, :], tau)
            V_mean = V_mean + np.real(Delta)
        V_mean = c * V_mean / N_samples
        U0 = Stiefel_Exp(U0, V_mean)
        # calculate error
        err = np.linalg.norm(V_mean, "fro")
        errs.append(err)
        count += 1
        print(f"count = {count}, error = {err}")
    frechet_mean = U0
    return frechet_mean, errs
