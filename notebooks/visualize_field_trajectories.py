# %%
# %% [markdown]
# # Visualize Field Trajectories
#
# This notebook visualizes decoded field trajectories from `generate_full_trajectories.py`,
# matching the evaluation plots from `train_latent_msbm.py`:
# - Forward vs reference comparison
# - Forward policy field snapshots
# - Backward policy field snapshots
# - Backward vs reference comparison
# - Single-sample marginal realizations
#
# ## Two modes:
# 1. **Standard mode**: Visualize multiple different samples
# 2. **Realizations mode**: Visualize multiple SDE runs from the SAME initial condition
#    (proper stochasticity visualization - see instructions below)
#
# ## How to generate realizations:
# ```bash
# python scripts/fae/generate_full_trajectories.py \
#     --run_dir results/your_run \
#     --n_realizations 8 \
#     --realization_sample_idx 0 \
#     --direction backward \
#     --save_decoded \
#     --output_name realizations_backward.npz
# ```

# %%
from __future__ import annotations

import sys
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np

# Make repo importable
path_root = Path(__file__).resolve().parent.parent
print(f"Adding repo root to sys.path: {path_root}")
if str(path_root) not in sys.path:
    sys.path.insert(0, str(path_root))

from scripts.images.field_visualization import (
    format_for_paper,
    plot_field_snapshots,
    plot_sample_comparison_grid,
)

print("Imports successful!")

# %%
format_for_paper()

# %% [markdown]
# ## Configuration

# %%
# Path to the .npz file generated by generate_full_trajectories.py
traj_path = Path("/data1/jy384/research/MMSFM/results/fae_latent_msbm_var0625/realizations_backward.npz")

# Visualization settings
n_samples_visualize = 4  # Number of samples to show in comparison grids
n_samples_snapshots = 4  # Number of samples to show in field snapshots (can be different)
n_single_sample_realizations = 8  # Number of realizations to show for single-sample marginal plot

viz_dir = traj_path.parent / "field_viz"
viz_dir.mkdir(parents=True, exist_ok=True)
print(f"Saving figures to: {viz_dir}")

# %% [markdown]
# ## Load trajectory data

# %%
if not traj_path.exists():
    raise FileNotFoundError(
        f"Trajectory file not found: {traj_path}\n"
        "Run scripts/fae/generate_full_trajectories.py with --save_decoded first."
    )

npz = np.load(traj_path, allow_pickle=True)

# Load metadata
zt = np.asarray(npz["zt"], dtype=np.float32) if "zt" in npz else None
grid_coords = np.asarray(npz["grid_coords"], dtype=np.float32) if "grid_coords" in npz else None
sample_indices = np.asarray(npz["sample_indices"], dtype=np.int64) if "sample_indices" in npz else None

# Check if this is a realizations file (multiple SDE runs from same initial condition)
is_realizations = bool(npz["is_realizations"].item()) if "is_realizations" in npz else False
base_sample_idx = int(npz["base_sample_idx"].item()) if "base_sample_idx" in npz else None

# Load decoded fields (full trajectories)
fields_f_full = np.asarray(npz["fields_forward_full"], dtype=np.float32) if "fields_forward_full" in npz else None
fields_b_full = np.asarray(npz["fields_backward_full"], dtype=np.float32) if "fields_backward_full" in npz else None

# Load decoded fields (knots only, if available)
latent_f_knots = np.asarray(npz["latent_forward_knots"], dtype=np.float32) if "latent_forward_knots" in npz else None
latent_b_knots = np.asarray(npz["latent_backward_knots"], dtype=np.float32) if "latent_backward_knots" in npz else None

npz.close()

print("Loaded trajectory data:")
if is_realizations:
    print(f"  Mode: REALIZATIONS (multiple SDE runs from same initial sample {base_sample_idx})")
if fields_f_full is not None:
    print(f"  Forward fields (full): {fields_f_full.shape} (T_steps, N, P, 1)")
if fields_b_full is not None:
    print(f"  Backward fields (full): {fields_b_full.shape} (T_steps, N, P, 1)")
if zt is not None:
    print(f"  zt: {np.round(zt, 4).tolist()}")

if fields_f_full is None and fields_b_full is None:
    raise ValueError(
        "No decoded fields found in trajectory file.\n"
        "Rerun generate_full_trajectories.py with --save_decoded flag."
    )

# %% [markdown]
# ## Visualization Mode Summary

# %%
print("\n" + "=" * 70)
print("VISUALIZATION MODE")
print("=" * 70)
if is_realizations:
    print("✓ REALIZATIONS MODE")
    print(f"  - Base sample index: {base_sample_idx}")
    print(f"  - All trajectories start from the SAME initial condition")
    print(f"  - Visualizations show stochasticity due to different Brownian noise")
else:
    print("  STANDARD MODE")
    print(f"  - Showing different samples from the dataset")
    print(f"  - Each trajectory has a different initial condition")
    print()
    print("  ⚠️  To visualize stochasticity properly, generate realizations:")
    print("     python scripts/fae/generate_full_trajectories.py \\")
    print("         --run_dir <dir> --n_realizations 8 \\")
    print("         --realization_sample_idx 0 --direction backward \\")
    print("         --save_decoded --output_name realizations_backward.npz")
print("=" * 70)

# %% [markdown]
# ## Load reference fields from training data
#
# To create comparison plots, we need the reference fields from the original dataset.

# %%
run_dir = traj_path.parent
latents_path = run_dir / "fae_latents.npz"

if not latents_path.exists():
    raise FileNotFoundError(f"Missing {latents_path} - cannot load resolution metadata.")

lat_npz = np.load(latents_path, allow_pickle=True)
resolution = int(lat_npz["resolution"].item()) if "resolution" in lat_npz else None
dataset_meta = lat_npz["dataset_meta"].item() if "dataset_meta" in lat_npz else {}
split = lat_npz["split"].item() if "split" in lat_npz else {}
lat_npz.close()

if resolution is None:
    raise ValueError("Could not determine resolution from fae_latents.npz")

print(f"Resolution: {resolution}")
print(f"Split info: {split}")

# Load the original dataset to get reference fields
from scripts.pca.pca_visualization_utils import parse_args_file

args_path = run_dir / "args.txt"
if not args_path.exists():
    raise FileNotFoundError(f"Missing args.txt in {run_dir}")

train_cfg = parse_args_file(args_path)
data_path = train_cfg.get("data_path")
held_out_indices_str = str(train_cfg.get("held_out_indices", ""))
held_out_times_str = str(train_cfg.get("held_out_times", ""))

print(f"Loading dataset from: {data_path}")

from scripts.fae.fae_naive.train_attention import (
    load_dataset_metadata,
    parse_held_out_indices_arg,
    parse_held_out_times_arg,
)
from scripts.fae.multiscale_dataset_naive import load_training_time_data_naive

dataset_meta_full = load_dataset_metadata(data_path)

held_out_indices = None
if held_out_indices_str.strip():
    held_out_indices = parse_held_out_indices_arg(held_out_indices_str)
elif held_out_times_str.strip():
    if dataset_meta_full.get("times_normalized") is None:
        raise ValueError("--held_out_times requires times_normalized in the dataset.")
    held_out_indices = parse_held_out_times_arg(held_out_times_str, dataset_meta_full["times_normalized"])

time_data = load_training_time_data_naive(data_path, held_out_indices=held_out_indices)
time_data_sorted = sorted(time_data, key=lambda d: float(d.get("t_norm", 0.0)))

print(f"Loaded {len(time_data_sorted)} time marginals from dataset")

# %% [markdown]
# ## Extract reference fields for selected samples

# %%
def _extract_reference_fields(
    time_data_sorted: list[dict],
    sample_indices: np.ndarray,
    resolution: int,
    train_ratio: float,
) -> np.ndarray:
    """Extract reference fields (T, N, res, res) for the selected sample indices."""
    refs = []
    for d in time_data_sorted:
        u_all = np.asarray(d["u"], dtype=np.float32)  # (N_total, P, 1)

        # These indices are from the training split
        n_total = u_all.shape[0]
        n_train = int(np.floor(n_total * train_ratio))
        n_train = max(1, min(n_train, n_total - 1))

        u_train = u_all[:n_train]  # (N_train, P, 1)

        # Select the specific samples
        u_selected = u_train[sample_indices]  # (N, P, 1)
        u_selected = u_selected[..., 0]  # (N, P)
        u_selected = u_selected.reshape(u_selected.shape[0], resolution, resolution)
        refs.append(u_selected)

    return np.stack(refs, axis=0)  # (T, N, res, res)


if sample_indices is not None:
    if train_cfg.get("train_ratio") is not None:
        train_ratio = float(train_cfg["train_ratio"])
    else:
        train_ratio = 0.8

    # In realizations mode, sample_indices is a single element array
    # We need to extract the reference field for just that one sample
    if is_realizations and len(sample_indices) == 1:
        ref_idx = np.array([sample_indices[0]], dtype=np.int64)
    else:
        ref_idx = sample_indices

    reference_fields = _extract_reference_fields(
        time_data_sorted, ref_idx, resolution, train_ratio
    )
    print(f"Reference fields: {reference_fields.shape} (T, N, res, res)")

    # For realizations mode, we only have one reference sample
    if is_realizations:
        print(f"  (Single reference sample {base_sample_idx} for all realizations)")
else:
    print("Warning: No sample_indices found in trajectory file, cannot create reference comparison.")
    reference_fields = None

# %% [markdown]
# ## Helper functions

# %%
def _flat_fields_to_grid(fields: np.ndarray, resolution: int) -> np.ndarray:
    """Convert flat fields (T,N,P,1) or (T,N,P) -> (T,N,res,res)."""
    if fields.ndim == 4 and fields.shape[-1] == 1:
        fields = fields[..., 0]
    if fields.ndim != 3:
        raise ValueError(f"Expected fields with shape (T,N,P[,1]); got {tuple(fields.shape)}")
    T, N, P = fields.shape
    if resolution * resolution != P:
        raise ValueError(f"resolution^2 must match P. Got resolution={resolution}, P={P}.")
    return fields.reshape(T, N, resolution, resolution)


def _extract_marginal_frames(fields: np.ndarray, n_marginals: int) -> np.ndarray:
    """Extract frames at marginal times from full trajectory.

    Parameters
    ----------
    fields : (T_full, N, res, res)
        Full trajectory fields
    n_marginals : int
        Number of marginal time points

    Returns
    -------
    marginal_fields : (T_marginals, N, res, res)
        Fields at marginal times only
    """
    n_steps_full = fields.shape[0]
    n_intervals = n_marginals - 1
    steps_per_interval = (n_steps_full - 1) // n_intervals

    marginal_indices = [i * steps_per_interval for i in range(n_marginals)]
    marginal_indices[-1] = n_steps_full - 1  # Ensure last frame is exactly the final one

    return fields[marginal_indices]


# Convert fields to grid format
fields_f = _flat_fields_to_grid(fields_f_full, resolution) if fields_f_full is not None else None
fields_b = _flat_fields_to_grid(fields_b_full, resolution) if fields_b_full is not None else None

print("\nField grids:")
if fields_f is not None:
    print(f"  Forward: {fields_f.shape} (T, N, res, res)")
if fields_b is not None:
    print(f"  Backward: {fields_b.shape} (T, N, res, res)")

# %% [markdown]
# ## Visualizations matching train_latent_msbm.py evaluation
#
# These use the same plotting functions as the stage evaluation callback.

# %% [markdown]
# ### 1. Reference field snapshots

# %%
if reference_fields is not None:
    print("\nGenerating reference field snapshots...")

    n_ref = min(n_samples_snapshots, reference_fields.shape[1])

    plot_field_snapshots(
        reference_fields[:, :n_ref],
        zt.tolist(),
        str(viz_dir),
        None,  # wandb run (not needed for standalone visualization)
        n_samples=n_ref,
        score=False,
        filename_prefix="REFERENCE_field_snapshots",
    )
    print(f"  Saved to {viz_dir}/REFERENCE_field_snapshots_*.png")

# %% [markdown]
# ### 2. Forward policy field snapshots

# %%
if fields_f is not None:
    print("\nGenerating forward policy field snapshots...")

    fields_f_marginals = _extract_marginal_frames(fields_f, len(zt))
    n_fwd = min(n_samples_snapshots, fields_f_marginals.shape[1])

    if is_realizations:
        print(f"  Showing {n_fwd} realizations from same initial sample {base_sample_idx}")
    else:
        print(f"  Showing {n_fwd} different samples")

    plot_field_snapshots(
        fields_f_marginals[:, :n_fwd],
        zt.tolist(),
        str(viz_dir),
        None,
        n_samples=n_fwd,
        score=False,
        filename_prefix="forward_policy_field_snapshots",
    )
    print(f"  Saved to {viz_dir}/forward_policy_field_snapshots_*.png")

# %% [markdown]
# ### 3. Backward policy field snapshots

# %%
if fields_b is not None:
    print("\nGenerating backward policy field snapshots...")

    fields_b_marginals = _extract_marginal_frames(fields_b, len(zt))
    n_bwd = min(n_samples_snapshots, fields_b_marginals.shape[1])

    if is_realizations:
        print(f"  Showing {n_bwd} realizations from same initial sample {base_sample_idx}")
    else:
        print(f"  Showing {n_bwd} different samples")

    plot_field_snapshots(
        fields_b_marginals[:, :n_bwd],
        zt.tolist(),
        str(viz_dir),
        None,
        n_samples=n_bwd,
        score=False,
        filename_prefix="backward_policy_field_snapshots",
    )
    print(f"  Saved to {viz_dir}/backward_policy_field_snapshots_*.png")

# %% [markdown]
# ### 4. Forward vs Reference comparison

# %%
if fields_f is not None and reference_fields is not None:
    print("\nGenerating forward vs reference comparison...")

    fields_f_marginals = _extract_marginal_frames(fields_f, len(zt))

    # Handle realizations mode: broadcast single reference to match multiple realizations
    if is_realizations and reference_fields.shape[1] == 1:
        n_comp = min(n_samples_visualize, fields_f_marginals.shape[1])
        # Repeat the single reference sample n_comp times for comparison
        target_list = [
            np.tile(reference_fields[t, 0:1], (n_comp, 1, 1))
            for t in range(reference_fields.shape[0])
        ]
        print(f"  Realizations mode: comparing {n_comp} realizations against same reference sample {base_sample_idx}")
    else:
        n_comp = min(n_samples_visualize, fields_f_marginals.shape[1], reference_fields.shape[1])
        target_list = [reference_fields[t, :n_comp] for t in range(reference_fields.shape[0])]

    plot_sample_comparison_grid(
        target_list,
        fields_f_marginals[:, :n_comp],
        zt.tolist(),
        str(viz_dir),
        None,
        score=False,
        n_samples=n_comp,
        filename_prefix="forward_vs_reference",
    )
    print(f"  Saved to {viz_dir}/forward_vs_reference_*.png")

# %% [markdown]
# ### 5. Backward vs Reference comparison

# %%
if fields_b is not None and reference_fields is not None:
    print("\nGenerating backward vs reference comparison...")

    fields_b_marginals = _extract_marginal_frames(fields_b, len(zt))

    # Handle realizations mode: broadcast single reference to match multiple realizations
    if is_realizations and reference_fields.shape[1] == 1:
        n_comp = min(n_samples_visualize, fields_b_marginals.shape[1])
        # Repeat the single reference sample n_comp times for comparison
        target_list = [
            np.tile(reference_fields[t, 0:1], (n_comp, 1, 1))
            for t in range(reference_fields.shape[0])
        ]
        print(f"  Realizations mode: comparing {n_comp} realizations against same reference sample {base_sample_idx}")
    else:
        n_comp = min(n_samples_visualize, fields_b_marginals.shape[1], reference_fields.shape[1])
        target_list = [reference_fields[t, :n_comp] for t in range(reference_fields.shape[0])]

    plot_sample_comparison_grid(
        target_list,
        fields_b_marginals[:, :n_comp],
        zt.tolist(),
        str(viz_dir),
        None,
        score=False,
        n_samples=n_comp,
        filename_prefix="backward_vs_reference",
    )
    print(f"  Saved to {viz_dir}/backward_vs_reference_*.png")

# %% [markdown]
# ### 6. Single sample marginal realizations (Backward policy)
#
# This shows multiple realizations of a single sample at marginal times,
# demonstrating the stochasticity of the backward policy.
#
# **Proper visualization**: All realizations start from the SAME initial latent code at t=1.00,
# showing how the SDE produces different trajectories due to Brownian noise.

# %%
if fields_b is not None:
    print("\nGenerating single-sample marginal realizations (backward policy)...")

    n_marginals = len(zt)
    fields_b_marginals = _extract_marginal_frames(fields_b, n_marginals)

    # If this is a realizations file, all samples are realizations of the same initial condition
    if is_realizations:
        n_real = min(n_single_sample_realizations, fields_b_marginals.shape[1])
        title = (
            f"Backward Policy: {n_real} SDE Realizations from Same Initial Sample\n"
            f"Sample index {base_sample_idx} at t={zt[-1]:.2f} → Multiple trajectories showing stochasticity"
        )
        ylabel_prefix = "Realization"

        # Get the reference field for the base sample
        if reference_fields is not None and base_sample_idx is not None:
            # reference_fields was extracted for sample_indices, but all are the same in realizations mode
            ref_sample = reference_fields[:, 0]  # (T, res, res) - just one reference sample
        else:
            ref_sample = None
    else:
        # Regular mode: just show first N samples (not true realizations)
        n_real = min(n_single_sample_realizations, fields_b_marginals.shape[1])
        title = (
            f"Backward Policy: {n_real} Different Samples at Marginal Times\n"
            f"(Warning: These are different samples, not realizations from same initial condition)"
        )
        ylabel_prefix = "Sample"
        ref_sample = None

    # Create a grid showing how realizations evolve through marginal times
    # Format: rows = realizations, columns = time marginals (+ optional reference row)
    n_rows = n_real + (1 if is_realizations and ref_sample is not None else 0)

    fig, axes = plt.subplots(
        n_rows, n_marginals,
        figsize=(2.5 * n_marginals, 2.5 * n_rows),
        squeeze=False,
    )

    # Add reference row if available (for realizations mode)
    row_offset = 0
    if is_realizations and ref_sample is not None:
        for t in range(n_marginals):
            ax = axes[0, t]
            field = ref_sample[t]

            im = ax.imshow(field, cmap="RdBu_r", origin="lower")
            ax.set_xticks([])
            ax.set_yticks([])

            if t == 0:
                ax.set_ylabel("Reference\n(Ground Truth)", fontsize=10, fontweight="bold")
            ax.set_title(f"t={zt[t]:.2f}", fontsize=10, fontweight="bold")

            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)

        row_offset = 1

    # Add realization rows
    for i in range(n_real):
        for t in range(n_marginals):
            ax = axes[i + row_offset, t]
            field = fields_b_marginals[t, i]

            im = ax.imshow(field, cmap="RdBu_r", origin="lower")
            ax.set_xticks([])
            ax.set_yticks([])

            if row_offset == 0 and i == 0:
                ax.set_title(f"t={zt[t]:.2f}", fontsize=10)
            if t == 0:
                ax.set_ylabel(f"{ylabel_prefix} {i+1}", fontsize=10)

            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)

    fig.suptitle(title, fontsize=12, y=0.995)
    fig.tight_layout(rect=[0, 0, 1, 0.99])

    save_path = viz_dir / "backward_single_sample_marginal_realizations.png"
    fig.savefig(save_path, dpi=150, bbox_inches="tight")
    plt.show()

    print(f"  Saved to {save_path}")

    if not is_realizations:
        print(
            "\n  ⚠️  WARNING: To properly visualize stochasticity, regenerate trajectories with:\n"
            "     python scripts/fae/generate_full_trajectories.py --run_dir <dir> \\\n"
            "         --n_realizations 8 --realization_sample_idx 0 \\\n"
            "         --direction backward --save_decoded \\\n"
            "         --output_name realizations_backward.npz\n"
        )

# %% [markdown]
# ## Summary

# %%
print("\n" + "=" * 70)
print("VISUALIZATION SUMMARY")
print("=" * 70)
print(f"Output directory: {viz_dir}")
print(f"Mode: {'REALIZATIONS' if is_realizations else 'STANDARD'}")
print("\nGenerated plots:")
print("  1. REFERENCE_field_snapshots_*.png")
print("     - Reference fields from dataset at marginal times")
print("  2. forward_policy_field_snapshots_*.png")
print("     - Forward policy generated fields at marginal times")
print("  3. backward_policy_field_snapshots_*.png")
print("     - Backward policy generated fields at marginal times")
print("  4. forward_vs_reference_*.png")
print("     - Side-by-side comparison of forward policy vs reference")
print("  5. backward_vs_reference_*.png")
print("     - Side-by-side comparison of backward policy vs reference")
print("  6. backward_single_sample_marginal_realizations.png")
if is_realizations:
    print("     - Multiple SDE realizations from SAME initial condition (proper stochasticity viz)")
else:
    print("     - Multiple different samples (NOT true realizations)")
print("=" * 70)
print("\nAll plots match the evaluation format from train_latent_msbm.py")

if not is_realizations:
    print("\n" + "=" * 70)
    print("HOW TO GENERATE PROPER REALIZATIONS")
    print("=" * 70)
    print("To properly visualize the stochasticity of the backward policy,")
    print("generate multiple SDE runs from the same initial condition:")
    print("\n  python scripts/fae/generate_full_trajectories.py \\")
    print("      --run_dir <your_run_directory> \\")
    print("      --n_realizations 8 \\")
    print("      --realization_sample_idx 0 \\")
    print("      --direction backward \\")
    print("      --save_decoded \\")
    print("      --output_name realizations_backward.npz")
    print("\nThen visualize with:")
    print("  traj_path = Path('<run_dir>/realizations_backward.npz')")
    print("=" * 70)

# %%
